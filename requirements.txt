# Core dependencies
torch>=2.0.0
transformers>=4.30.0
accelerate>=0.20.0
peft>=0.7.0  # For LoRA efficient fine-tuning
bitsandbytes>=0.41.0  # For 4-bit quantization

# Testing
pytest>=7.0.0

# Utilities
numpy<2.0.0,>=1.24.0
tqdm>=4.65.0

# Optional: For better performance
sentencepiece>=0.1.99
protobuf>=3.20.0

# Optional: For API-based problem generation
openai>=1.0.0  # For GPT-4 problem generation
anthropic>=0.18.0  # For Claude problem generation
groq>=0.4.0  # For FREE Llama 3.1 70B problem generation
